{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit_predict(X_train, y_train):\n",
    "    kf = StratifiedKFold(n_splits = 10, random_state=42, shuffle=True)\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1s = []\n",
    "    cnt = 0\n",
    "    for train_index, test_index in kf.split(X_train, y_train):\n",
    "        cnt = cnt+1\n",
    "        print(\"-----------------------------------------------\")\n",
    "        print(\"Running for fold \", str(cnt))\n",
    "        x_train = X_train.iloc[train_index]\n",
    "        Y_train = y_train.iloc[train_index]\n",
    "        x_test = X_train.iloc[test_index]\n",
    "        Y_test = y_train.iloc[test_index]\n",
    "        model = xgb.XGBClassifier(max_depth=3,learning_rate=0.1).fit(x_train, Y_train)\n",
    "        predictions = model.predict(x_test)\n",
    "        accuracies.append(accuracy_score(predictions, Y_test))\n",
    "        precisions.append(np.mean(precision_score(predictions, Y_test, average = None)))\n",
    "        recalls.append(np.mean(recall_score(predictions, Y_test, average = None)))\n",
    "        f1s.append(np.mean(f1_score(predictions, Y_test, average = None)))\n",
    "        print(\"Accuracy : \", accuracy_score(predictions, Y_test))\n",
    "        print(\"Precision : \", precision_score(predictions, Y_test, average = None))\n",
    "        print(\"Recall : \", recall_score(predictions, Y_test, average = None))\n",
    "        print(\"F1 : \", f1_score(predictions, Y_test, average = None))\n",
    "        print(\"-----------------------------------------------\")\n",
    "    print('Final Mean Scores ---------------------------------')\n",
    "    print('Mean Accuracy Score : ', sum(accuracies)/len(accuracies))\n",
    "    precision = sum(precisions)/len(precisions)\n",
    "    recall = sum(recalls)/len(recalls)\n",
    "    f1 = sum(f1s)/len(f1s)\n",
    "    print('Mean Precision Score : ', np.mean(precision))\n",
    "    print('Mean Recall Score : ', np.mean(recall))\n",
    "    print('Mean F1 Score : ', np.mean(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_categorical_features(df):\n",
    "    df[df.select_dtypes(['object']).columns] = df.select_dtypes(['object']).apply(lambda x: x.astype('category'))\n",
    "    cols = df.columns\n",
    "\n",
    "    num_cols = df._get_numeric_data().columns\n",
    "    print(list(set(cols) - set(num_cols)))\n",
    "    return (list(set(cols) - set(num_cols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical_features(df):\n",
    "    ONE_HOT_COLS = find_categorical_features(df)\n",
    "    print(\"Starting DF shape: %d, %d\" % df.shape)\n",
    "    \n",
    "    for col in ONE_HOT_COLS:\n",
    "        s = df[col].unique()\n",
    "\n",
    "        # Create a One Hot Dataframe with 1 row for each unique value\n",
    "        one_hot_df = pd.get_dummies(s, prefix='%s_' % col)\n",
    "        one_hot_df[col] = s\n",
    "\n",
    "        print(\"Adding One Hot values for %s (the column has %d unique values)\" % (col, len(s)))\n",
    "        pre_len = len(df)\n",
    "\n",
    "        # Merge the one hot columns\n",
    "        df = df.merge(one_hot_df, on=[col], how=\"left\")\n",
    "        assert len(df) == pre_len\n",
    "        print(df.shape)\n",
    "    df.drop(ONE_HOT_COLS, axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv('iris.data', header=None)\n",
    "column_names = ['SepalLength','SepalWidth','PetalLength','PetalWidth','Class']\n",
    "iris.columns = column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SepalLength  SepalWidth  PetalLength  PetalWidth           Class\n",
       "0            5.1         3.5          1.4         0.2     Iris-setosa\n",
       "1            4.9         3.0          1.4         0.2     Iris-setosa\n",
       "2            4.7         3.2          1.3         0.2     Iris-setosa\n",
       "3            4.6         3.1          1.5         0.2     Iris-setosa\n",
       "4            5.0         3.6          1.4         0.2     Iris-setosa\n",
       "..           ...         ...          ...         ...             ...\n",
       "145          6.7         3.0          5.2         2.3  Iris-virginica\n",
       "146          6.3         2.5          5.0         1.9  Iris-virginica\n",
       "147          6.5         3.0          5.2         2.0  Iris-virginica\n",
       "148          6.2         3.4          5.4         2.3  Iris-virginica\n",
       "149          5.9         3.0          5.1         1.8  Iris-virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = iris.Class\n",
    "iris.drop(['Class'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "Running for fold  1\n",
      "[21:49:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  1.0\n",
      "Precision :  [1. 1. 1.]\n",
      "Recall :  [1. 1. 1.]\n",
      "F1 :  [1. 1. 1.]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nihal\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\nihal\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  2\n",
      "[21:49:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  0.9333333333333333\n",
      "Precision :  [1.  1.  0.8]\n",
      "Recall :  [1.         0.83333333 1.        ]\n",
      "F1 :  [1.         0.90909091 0.88888889]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  3\n",
      "[21:49:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  1.0\n",
      "Precision :  [1. 1. 1.]\n",
      "Recall :  [1. 1. 1.]\n",
      "F1 :  [1. 1. 1.]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  4\n",
      "[21:49:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  0.9333333333333333\n",
      "Precision :  [1.  1.  0.8]\n",
      "Recall :  [1.         0.83333333 1.        ]\n",
      "F1 :  [1.         0.90909091 0.88888889]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  5\n",
      "[21:49:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  0.8666666666666667\n",
      "Precision :  [1.  0.8 0.8]\n",
      "Recall :  [1.  0.8 0.8]\n",
      "F1 :  [1.  0.8 0.8]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  6\n",
      "[21:49:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  0.8666666666666667\n",
      "Precision :  [1.  0.6 1. ]\n",
      "Recall :  [1.         1.         0.71428571]\n",
      "F1 :  [1.         0.75       0.83333333]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  7\n",
      "[21:49:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  1.0\n",
      "Precision :  [1. 1. 1.]\n",
      "Recall :  [1. 1. 1.]\n",
      "F1 :  [1. 1. 1.]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  8\n",
      "[21:49:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  1.0\n",
      "Precision :  [1. 1. 1.]\n",
      "Recall :  [1. 1. 1.]\n",
      "F1 :  [1. 1. 1.]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  9\n",
      "[21:49:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  0.9333333333333333\n",
      "Precision :  [1.  0.8 1. ]\n",
      "Recall :  [1.         1.         0.83333333]\n",
      "F1 :  [1.         0.88888889 0.90909091]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  10\n",
      "[21:49:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  0.9333333333333333\n",
      "Precision :  [1.  1.  0.8]\n",
      "Recall :  [1.         0.83333333 1.        ]\n",
      "F1 :  [1.         0.90909091 0.88888889]\n",
      "-----------------------------------------------\n",
      "Final Mean Scores ---------------------------------\n",
      "Mean Accuracy Score :  0.9466666666666669\n",
      "Mean Precision Score :  0.9466666666666667\n",
      "Mean Recall Score :  0.9549206349206351\n",
      "Mean F1 Score :  0.9458417508417508\n"
     ]
    }
   ],
   "source": [
    "model_fit_predict(iris, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = pd.read_csv('wine.data', header=None)\n",
    "column_names = ['Alcohol','Malic acid','Ash','Alcalinity of ash','Magnesium','Total phenols','Flavanoids','Nonflavanoid phenols','Proanthocyanins' ,'Color intensity','Hue' ,'OD280/OD315 of diluted wines','Proline','target']\n",
    "wine.columns = column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  Total phenols  \\\n",
       "0      14.23        1.71  2.43               15.6        127           2.80   \n",
       "1      13.20        1.78  2.14               11.2        100           2.65   \n",
       "2      13.16        2.36  2.67               18.6        101           2.80   \n",
       "3      14.37        1.95  2.50               16.8        113           3.85   \n",
       "4      13.24        2.59  2.87               21.0        118           2.80   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "173    13.71        5.65  2.45               20.5         95           1.68   \n",
       "174    13.40        3.91  2.48               23.0        102           1.80   \n",
       "175    13.27        4.28  2.26               20.0        120           1.59   \n",
       "176    13.17        2.59  2.37               20.0        120           1.65   \n",
       "177    14.13        4.10  2.74               24.5         96           2.05   \n",
       "\n",
       "     Flavanoids  Nonflavanoid phenols  Proanthocyanins  Color intensity   Hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     OD280/OD315 of diluted wines  Proline  target  \n",
       "0                            3.92     1065       1  \n",
       "1                            3.40     1050       1  \n",
       "2                            3.17     1185       1  \n",
       "3                            3.45     1480       1  \n",
       "4                            2.93      735       1  \n",
       "..                            ...      ...     ...  \n",
       "173                          1.74      740       3  \n",
       "174                          1.56      750       3  \n",
       "175                          1.56      835       3  \n",
       "176                          1.62      840       3  \n",
       "177                          1.60      560       3  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = wine.target\n",
    "wine.drop(['target'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "Running for fold  1\n",
      "[21:50:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy : "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nihal\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\nihal\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1.0\n",
      "Precision :  [1. 1. 1.]\n",
      "Recall :  [1. 1. 1.]\n",
      "F1 :  [1. 1. 1.]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  2\n",
      "[21:50:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  0.9444444444444444\n",
      "Precision :  [1.         0.85714286 1.        ]\n",
      "Recall :  [1.         1.         0.83333333]\n",
      "F1 :  [1.         0.92307692 0.90909091]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  3\n",
      "[21:50:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  0.8888888888888888\n",
      "Precision :  [1.         0.85714286 0.8       ]\n",
      "Recall :  [0.85714286 0.85714286 1.        ]\n",
      "F1 :  [0.92307692 0.85714286 0.88888889]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  4\n",
      "[21:50:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  1.0\n",
      "Precision :  [1. 1. 1.]\n",
      "Recall :  [1. 1. 1.]\n",
      "F1 :  [1. 1. 1.]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  5\n",
      "[21:50:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  0.9444444444444444\n",
      "Precision :  [1.         0.85714286 1.        ]\n",
      "Recall :  [1.         1.         0.83333333]\n",
      "F1 :  [1.         0.92307692 0.90909091]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  6\n",
      "[21:50:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  1.0\n",
      "Precision :  [1. 1. 1.]\n",
      "Recall :  [1. 1. 1.]\n",
      "F1 :  [1. 1. 1.]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  7\n",
      "[21:50:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  1.0\n",
      "Precision :  [1. 1. 1.]\n",
      "Recall :  [1. 1. 1.]\n",
      "F1 :  [1. 1. 1.]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  8\n",
      "[21:50:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  0.8333333333333334\n",
      "Precision :  [0.66666667 0.85714286 1.        ]\n",
      "Recall :  [0.8        0.85714286 0.83333333]\n",
      "F1 :  [0.72727273 0.85714286 0.90909091]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  9\n",
      "[21:50:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  1.0\n",
      "Precision :  [1. 1. 1.]\n",
      "Recall :  [1. 1. 1.]\n",
      "F1 :  [1. 1. 1.]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  10\n",
      "[21:50:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  1.0\n",
      "Precision :  [1. 1. 1.]\n",
      "Recall :  [1. 1. 1.]\n",
      "F1 :  [1. 1. 1.]\n",
      "-----------------------------------------------\n",
      "Final Mean Scores ---------------------------------\n",
      "Mean Accuracy Score :  0.961111111111111\n",
      "Mean Precision Score :  0.9631746031746031\n",
      "Mean Recall Score :  0.9623809523809523\n",
      "Mean F1 Score :  0.960898360898361\n"
     ]
    }
   ],
   "source": [
    "model_fit_predict(wine, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "zoo = pd.read_csv('zoo.data', header=None)\n",
    "column_names = ['hair','feathers','eggs','milk','airborne','aquatic','predator','toothed','backbone','breathes','enomous','fins','legs','tail','domestic','catsize','label']\n",
    "zoo.columns = column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = zoo.label\n",
    "zoo.drop(['label'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      4\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "96     1\n",
       "97     6\n",
       "98     1\n",
       "99     7\n",
       "100    2\n",
       "Name: label, Length: 101, dtype: int64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nihal\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\nihal\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "Running for fold  1\n",
      "[21:50:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nihal\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  1.0\n",
      "Precision :  [1. 1. 1. 1. 1. 1.]\n",
      "Recall :  [1. 1. 1. 1. 1. 1.]\n",
      "F1 :  [1. 1. 1. 1. 1. 1.]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  2\n",
      "[21:50:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  1.0\n",
      "Precision :  [1. 1. 1. 1. 1.]\n",
      "Recall :  [1. 1. 1. 1. 1.]\n",
      "F1 :  [1. 1. 1. 1. 1.]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  3\n",
      "[21:50:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nihal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\nihal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.9\n",
      "Precision :  [1. 1. 0. 1. 0. 1.]\n",
      "Recall :  [1. 1. 0. 1. 0. 1.]\n",
      "F1 :  [1. 1. 0. 1. 0. 1.]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  4\n",
      "[21:50:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  1.0\n",
      "Precision :  [1. 1. 1. 1. 1.]\n",
      "Recall :  [1. 1. 1. 1. 1.]\n",
      "F1 :  [1. 1. 1. 1. 1.]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  5\n",
      "[21:50:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  1.0\n",
      "Precision :  [1. 1. 1. 1. 1. 1.]\n",
      "Recall :  [1. 1. 1. 1. 1. 1.]\n",
      "F1 :  [1. 1. 1. 1. 1. 1.]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  6\n",
      "[21:50:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  1.0\n",
      "Precision :  [1. 1. 1. 1. 1. 1.]\n",
      "Recall :  [1. 1. 1. 1. 1. 1.]\n",
      "F1 :  [1. 1. 1. 1. 1. 1.]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  7\n",
      "[21:50:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  1.0\n",
      "Precision :  [1. 1. 1. 1. 1. 1.]\n",
      "Recall :  [1. 1. 1. 1. 1. 1.]\n",
      "F1 :  [1. 1. 1. 1. 1. 1.]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  8\n",
      "[21:50:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  0.9\n",
      "Precision :  [1. 1. 0. 1. 1. 1.]\n",
      "Recall :  [1.  1.  0.  1.  0.5 1. ]\n",
      "F1 :  [1.         1.         0.         1.         0.66666667 1.        ]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  9\n",
      "[21:50:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  0.8\n",
      "Precision :  [1. 1. 0. 1. 0. 1.]\n",
      "Recall :  [1.  1.  0.  0.5 0.  0.5]\n",
      "F1 :  [1.         1.         0.         0.66666667 0.         0.66666667]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  10\n",
      "[21:50:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  1.0\n",
      "Precision :  [1. 1. 1. 1. 1. 1.]\n",
      "Recall :  [1. 1. 1. 1. 1. 1.]\n",
      "F1 :  [1. 1. 1. 1. 1. 1.]\n",
      "-----------------------------------------------\n",
      "Final Mean Scores ---------------------------------\n",
      "Mean Accuracy Score :  0.9600000000000002\n",
      "Mean Precision Score :  0.9166666666666666\n",
      "Mean Recall Score :  0.8916666666666666\n",
      "Mean F1 Score :  0.9\n"
     ]
    }
   ],
   "source": [
    "model_fit_predict(zoo, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "banknote = pd.read_csv('banknote_authentication.data', header=None)\n",
    "column_names = ['variance of Wavelet Transformed image','skewness of Wavelet Transformed image','curtosis of Wavelet Transformed image','entropy of image','label']\n",
    "banknote.columns = column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance of Wavelet Transformed image</th>\n",
       "      <th>skewness of Wavelet Transformed image</th>\n",
       "      <th>curtosis of Wavelet Transformed image</th>\n",
       "      <th>entropy of image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.66610</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.16740</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.63830</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.52280</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.45520</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>0.40614</td>\n",
       "      <td>1.34920</td>\n",
       "      <td>-1.4501</td>\n",
       "      <td>-0.55949</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>-1.38870</td>\n",
       "      <td>-4.87730</td>\n",
       "      <td>6.4774</td>\n",
       "      <td>0.34179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>-3.75030</td>\n",
       "      <td>-13.45860</td>\n",
       "      <td>17.5932</td>\n",
       "      <td>-2.77710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>-3.56370</td>\n",
       "      <td>-8.38270</td>\n",
       "      <td>12.3930</td>\n",
       "      <td>-1.28230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>-2.54190</td>\n",
       "      <td>-0.65804</td>\n",
       "      <td>2.6842</td>\n",
       "      <td>1.19520</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1372 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      variance of Wavelet Transformed image  \\\n",
       "0                                   3.62160   \n",
       "1                                   4.54590   \n",
       "2                                   3.86600   \n",
       "3                                   3.45660   \n",
       "4                                   0.32924   \n",
       "...                                     ...   \n",
       "1367                                0.40614   \n",
       "1368                               -1.38870   \n",
       "1369                               -3.75030   \n",
       "1370                               -3.56370   \n",
       "1371                               -2.54190   \n",
       "\n",
       "      skewness of Wavelet Transformed image  \\\n",
       "0                                   8.66610   \n",
       "1                                   8.16740   \n",
       "2                                  -2.63830   \n",
       "3                                   9.52280   \n",
       "4                                  -4.45520   \n",
       "...                                     ...   \n",
       "1367                                1.34920   \n",
       "1368                               -4.87730   \n",
       "1369                              -13.45860   \n",
       "1370                               -8.38270   \n",
       "1371                               -0.65804   \n",
       "\n",
       "      curtosis of Wavelet Transformed image  entropy of image  label  \n",
       "0                                   -2.8073          -0.44699      0  \n",
       "1                                   -2.4586          -1.46210      0  \n",
       "2                                    1.9242           0.10645      0  \n",
       "3                                   -4.0112          -3.59440      0  \n",
       "4                                    4.5718          -0.98880      0  \n",
       "...                                     ...               ...    ...  \n",
       "1367                                -1.4501          -0.55949      1  \n",
       "1368                                 6.4774           0.34179      1  \n",
       "1369                                17.5932          -2.77710      1  \n",
       "1370                                12.3930          -1.28230      1  \n",
       "1371                                 2.6842           1.19520      1  \n",
       "\n",
       "[1372 rows x 5 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banknote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = banknote.label\n",
    "banknote.drop(['label'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "Running for fold  1\n",
      "[21:51:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  1.0\n",
      "Precision :  [1. 1.]\n",
      "Recall :  [1. 1.]\n",
      "F1 :  [1. 1.]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  2\n",
      "[21:51:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nihal\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\nihal\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.9927536231884058\n",
      "Precision :  [1.         0.98360656]\n",
      "Recall :  [0.98717949 1.        ]\n",
      "F1 :  [0.99354839 0.99173554]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  3\n",
      "[21:51:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  1.0\n",
      "Precision :  [1. 1.]\n",
      "Recall :  [1. 1.]\n",
      "F1 :  [1. 1.]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  4\n",
      "[21:51:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  1.0\n",
      "Precision :  [1. 1.]\n",
      "Recall :  [1. 1.]\n",
      "F1 :  [1. 1.]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  5\n",
      "[21:51:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  1.0\n",
      "Precision :  [1. 1.]\n",
      "Recall :  [1. 1.]\n",
      "F1 :  [1. 1.]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  6\n",
      "[21:51:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  1.0\n",
      "Precision :  [1. 1.]\n",
      "Recall :  [1. 1.]\n",
      "F1 :  [1. 1.]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  7\n",
      "[21:51:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  0.9854014598540146\n",
      "Precision :  [0.97368421 1.        ]\n",
      "Recall :  [1.         0.96825397]\n",
      "F1 :  [0.98666667 0.98387097]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  8\n",
      "[21:51:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  1.0\n",
      "Precision :  [1. 1.]\n",
      "Recall :  [1. 1.]\n",
      "F1 :  [1. 1.]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  9\n",
      "[21:51:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  1.0\n",
      "Precision :  [1. 1.]\n",
      "Recall :  [1. 1.]\n",
      "F1 :  [1. 1.]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  10\n",
      "[21:51:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  1.0\n",
      "Precision :  [1. 1.]\n",
      "Recall :  [1. 1.]\n",
      "F1 :  [1. 1.]\n",
      "-----------------------------------------------\n",
      "Final Mean Scores ---------------------------------\n",
      "Mean Accuracy Score :  0.997815508304242\n",
      "Mean Precision Score :  0.9978645383951683\n",
      "Mean Recall Score :  0.9977716727716729\n",
      "Mean F1 Score :  0.9977910779347731\n"
     ]
    }
   ],
   "source": [
    "model_fit_predict(banknote, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_knowledge = pd.read_csv('user-knowledge-modeling.data.txt', header=None)\n",
    "column_names = ['STG','SCG','STR','LPR','PEG','label']\n",
    "user_knowledge.columns = column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STG</th>\n",
       "      <th>SCG</th>\n",
       "      <th>STR</th>\n",
       "      <th>LPR</th>\n",
       "      <th>PEG</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>very_low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.90</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.33</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.30</td>\n",
       "      <td>Middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.24</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.58</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.60</td>\n",
       "      <td>Middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.77</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.26</td>\n",
       "      <td>Middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.74</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>258 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      STG   SCG   STR   LPR   PEG     label\n",
       "0    0.00  0.00  0.00  0.00  0.00  very_low\n",
       "1    0.08  0.08  0.10  0.24  0.90      High\n",
       "2    0.06  0.06  0.05  0.25  0.33       Low\n",
       "3    0.10  0.10  0.15  0.65  0.30    Middle\n",
       "4    0.08  0.08  0.08  0.98  0.24       Low\n",
       "..    ...   ...   ...   ...   ...       ...\n",
       "253  0.61  0.78  0.69  0.92  0.58      High\n",
       "254  0.78  0.61  0.71  0.19  0.60    Middle\n",
       "255  0.54  0.82  0.71  0.29  0.77      High\n",
       "256  0.50  0.75  0.81  0.61  0.26    Middle\n",
       "257  0.66  0.90  0.76  0.87  0.74      High\n",
       "\n",
       "[258 rows x 6 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = user_knowledge.label\n",
    "user_knowledge.drop(['label'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "Running for fold  1\n",
      "[21:52:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nihal\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\nihal\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.8076923076923077\n",
      "Precision :  [1.         1.         0.66666667 0.33333333]\n",
      "Recall :  [1.         0.61538462 1.         1.        ]\n",
      "F1 :  [1.         0.76190476 0.8        0.5       ]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  2\n",
      "[21:52:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  0.8846153846153846\n",
      "Precision :  [0.83333333 1.         0.88888889 0.66666667]\n",
      "Recall :  [1.         0.8        0.88888889 1.        ]\n",
      "F1 :  [0.90909091 0.88888889 0.88888889 0.8       ]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  3\n",
      "[21:52:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  0.9615384615384616\n",
      "Precision :  [0.83333333 1.         1.         1.        ]\n",
      "Recall :  [1.  1.  0.9 1. ]\n",
      "F1 :  [0.90909091 1.         0.94736842 1.        ]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  4\n",
      "[21:52:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  0.9230769230769231\n",
      "Precision :  [0.83333333 1.         0.88888889 1.        ]\n",
      "Recall :  [0.83333333 1.         0.88888889 1.        ]\n",
      "F1 :  [0.83333333 1.         0.88888889 1.        ]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  5\n",
      "[21:52:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  0.9615384615384616\n",
      "Precision :  [1.    0.875 1.    1.   ]\n",
      "Recall :  [1.         1.         1.         0.66666667]\n",
      "F1 :  [1.         0.93333333 1.         0.8       ]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  6\n",
      "[21:52:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  0.9615384615384616\n",
      "Precision :  [1.  1.  1.  0.5]\n",
      "Recall :  [1.         0.88888889 1.         1.        ]\n",
      "F1 :  [1.         0.94117647 1.         0.66666667]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  7\n",
      "[21:52:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  0.9615384615384616\n",
      "Precision :  [1.         1.         0.88888889 1.        ]\n",
      "Recall :  [1.         0.88888889 1.         1.        ]\n",
      "F1 :  [1.         0.94117647 0.94117647 1.        ]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  8\n",
      "[21:52:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  1.0\n",
      "Precision :  [1. 1. 1. 1.]\n",
      "Recall :  [1. 1. 1. 1.]\n",
      "F1 :  [1. 1. 1. 1.]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  9\n",
      "[21:52:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  0.96\n",
      "Precision :  [1.  1.  1.  0.5]\n",
      "Recall :  [1.  0.9 1.  1. ]\n",
      "F1 :  [1.         0.94736842 1.         0.66666667]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  10\n",
      "[21:52:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  0.92\n",
      "Precision :  [1.   1.   0.75 1.  ]\n",
      "Recall :  [1.         0.81818182 1.         1.        ]\n",
      "F1 :  [1.         0.9        0.85714286 1.        ]\n",
      "-----------------------------------------------\n",
      "Final Mean Scores ---------------------------------\n",
      "Mean Accuracy Score :  0.9341538461538461\n",
      "Mean Precision Score :  0.9114583333333334\n",
      "Mean Recall Score :  0.9522280497280498\n",
      "Mean F1 Score :  0.918054058944152\n"
     ]
    }
   ],
   "source": [
    "model_fit_predict(user_knowledge, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pima Indians Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "pima = pd.read_csv('pima-indians-diabetes.data', header=None)\n",
    "column_names = ['Number of times pregnant','Plasma glucose concentration a 2 hours in an oral glucose tolerance test','Diastolic blood pressure','Triceps skin fold thickness','2-Hour serum insulin','Body mass index','Diabetes pedigree function','Age','label']\n",
    "pima.columns = column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of times pregnant</th>\n",
       "      <th>Plasma glucose concentration a 2 hours in an oral glucose tolerance test</th>\n",
       "      <th>Diastolic blood pressure</th>\n",
       "      <th>Triceps skin fold thickness</th>\n",
       "      <th>2-Hour serum insulin</th>\n",
       "      <th>Body mass index</th>\n",
       "      <th>Diabetes pedigree function</th>\n",
       "      <th>Age</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Number of times pregnant  \\\n",
       "0                           6   \n",
       "1                           1   \n",
       "2                           8   \n",
       "3                           1   \n",
       "4                           0   \n",
       "..                        ...   \n",
       "763                        10   \n",
       "764                         2   \n",
       "765                         5   \n",
       "766                         1   \n",
       "767                         1   \n",
       "\n",
       "     Plasma glucose concentration a 2 hours in an oral glucose tolerance test  \\\n",
       "0                                                  148                          \n",
       "1                                                   85                          \n",
       "2                                                  183                          \n",
       "3                                                   89                          \n",
       "4                                                  137                          \n",
       "..                                                 ...                          \n",
       "763                                                101                          \n",
       "764                                                122                          \n",
       "765                                                121                          \n",
       "766                                                126                          \n",
       "767                                                 93                          \n",
       "\n",
       "     Diastolic blood pressure  Triceps skin fold thickness  \\\n",
       "0                          72                           35   \n",
       "1                          66                           29   \n",
       "2                          64                            0   \n",
       "3                          66                           23   \n",
       "4                          40                           35   \n",
       "..                        ...                          ...   \n",
       "763                        76                           48   \n",
       "764                        70                           27   \n",
       "765                        72                           23   \n",
       "766                        60                            0   \n",
       "767                        70                           31   \n",
       "\n",
       "     2-Hour serum insulin  Body mass index  Diabetes pedigree function  Age  \\\n",
       "0                       0             33.6                       0.627   50   \n",
       "1                       0             26.6                       0.351   31   \n",
       "2                       0             23.3                       0.672   32   \n",
       "3                      94             28.1                       0.167   21   \n",
       "4                     168             43.1                       2.288   33   \n",
       "..                    ...              ...                         ...  ...   \n",
       "763                   180             32.9                       0.171   63   \n",
       "764                     0             36.8                       0.340   27   \n",
       "765                   112             26.2                       0.245   30   \n",
       "766                     0             30.1                       0.349   47   \n",
       "767                     0             30.4                       0.315   23   \n",
       "\n",
       "     label  \n",
       "0        1  \n",
       "1        0  \n",
       "2        1  \n",
       "3        0  \n",
       "4        1  \n",
       "..     ...  \n",
       "763      0  \n",
       "764      0  \n",
       "765      0  \n",
       "766      1  \n",
       "767      0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pima.label\n",
    "pima.drop(['label'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "Running for fold  1\n",
      "[21:52:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  0.7922077922077922\n",
      "Precision :  [0.78       0.81481481]\n",
      "Recall :  [0.88636364 0.66666667]\n",
      "F1 :  [0.82978723 0.73333333]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  2\n",
      "[21:52:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nihal\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\nihal\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.7792207792207793\n",
      "Precision :  [0.92       0.51851852]\n",
      "Recall :  [0.77966102 0.77777778]\n",
      "F1 :  [0.8440367  0.62222222]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  3\n",
      "[21:52:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  0.7142857142857143\n",
      "Precision :  [0.84       0.48148148]\n",
      "Recall :  [0.75       0.61904762]\n",
      "F1 :  [0.79245283 0.54166667]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  4\n",
      "[21:52:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  0.8961038961038961\n",
      "Precision :  [0.96       0.77777778]\n",
      "Recall :  [0.88888889 0.91304348]\n",
      "F1 :  [0.92307692 0.84      ]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  5\n",
      "[21:52:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  0.8311688311688312\n",
      "Precision :  [0.9       0.7037037]\n",
      "Recall :  [0.8490566  0.79166667]\n",
      "F1 :  [0.87378641 0.74509804]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  6\n",
      "[21:52:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  0.7012987012987013\n",
      "Precision :  [0.8        0.51851852]\n",
      "Recall :  [0.75471698 0.58333333]\n",
      "F1 :  [0.77669903 0.54901961]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  7\n",
      "[21:52:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  0.7402597402597403\n",
      "Precision :  [0.84       0.55555556]\n",
      "Recall :  [0.77777778 0.65217391]\n",
      "F1 :  [0.80769231 0.6       ]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  8\n",
      "[21:52:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  0.7662337662337663\n",
      "Precision :  [0.78       0.74074074]\n",
      "Recall :  [0.84782609 0.64516129]\n",
      "F1 :  [0.8125     0.68965517]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  9\n",
      "[21:52:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  0.75\n",
      "Precision :  [0.8        0.65384615]\n",
      "Recall :  [0.81632653 0.62962963]\n",
      "F1 :  [0.80808081 0.64150943]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  10\n",
      "[21:52:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  0.6842105263157895\n",
      "Precision :  [0.8        0.46153846]\n",
      "Recall :  [0.74074074 0.54545455]\n",
      "F1 :  [0.76923077 0.5       ]\n",
      "-----------------------------------------------\n",
      "Final Mean Scores ---------------------------------\n",
      "Mean Accuracy Score :  0.765498974709501\n",
      "Mean Precision Score :  0.7323247863247863\n",
      "Mean Recall Score :  0.7457656591698896\n",
      "Mean F1 Score :  0.7349923741055028\n"
     ]
    }
   ],
   "source": [
    "model_fit_predict(pima, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "glass = pd.read_csv('glass.data', header=None)\n",
    "column_names = ['ID','RI', 'Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe', 'Class']\n",
    "glass.columns = column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "glass = glass.drop(columns=['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>1.51623</td>\n",
       "      <td>14.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.88</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.08</td>\n",
       "      <td>9.18</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>1.51685</td>\n",
       "      <td>14.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.99</td>\n",
       "      <td>73.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.40</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>1.52065</td>\n",
       "      <td>14.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.02</td>\n",
       "      <td>73.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.44</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>1.51651</td>\n",
       "      <td>14.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.94</td>\n",
       "      <td>73.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.48</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>1.51711</td>\n",
       "      <td>14.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.08</td>\n",
       "      <td>73.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.62</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          RI     Na    Mg    Al     Si     K    Ca    Ba   Fe  Class\n",
       "0    1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.00  0.0      1\n",
       "1    1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.00  0.0      1\n",
       "2    1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.00  0.0      1\n",
       "3    1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.00  0.0      1\n",
       "4    1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.00  0.0      1\n",
       "..       ...    ...   ...   ...    ...   ...   ...   ...  ...    ...\n",
       "209  1.51623  14.14  0.00  2.88  72.61  0.08  9.18  1.06  0.0      7\n",
       "210  1.51685  14.92  0.00  1.99  73.06  0.00  8.40  1.59  0.0      7\n",
       "211  1.52065  14.36  0.00  2.02  73.42  0.00  8.44  1.64  0.0      7\n",
       "212  1.51651  14.38  0.00  1.94  73.61  0.00  8.48  1.57  0.0      7\n",
       "213  1.51711  14.23  0.00  2.08  73.36  0.00  8.62  1.67  0.0      7\n",
       "\n",
       "[214 rows x 10 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = glass.Class\n",
    "glass.drop(['Class'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nihal\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\nihal\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "Running for fold  1\n",
      "[21:53:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nihal\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n",
      "C:\\Users\\nihal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.7727272727272727\n",
      "Precision :  [0.85714286 0.875      0.         1.         0.         1.        ]\n",
      "Recall :  [0.66666667 0.875      0.         0.5        0.         1.        ]\n",
      "F1 :  [0.75       0.875      0.         0.66666667 0.         1.        ]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  2\n",
      "[21:53:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  0.7272727272727273\n",
      "Precision :  [1.         0.625      0.         1.         1.         0.66666667]\n",
      "Recall :  [0.7        0.83333333 0.         0.5        1.         0.66666667]\n",
      "F1 :  [0.82352941 0.71428571 0.         0.66666667 1.         0.66666667]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  3\n",
      "[21:53:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  0.8636363636363636\n",
      "Precision :  [0.85714286 0.875      1.         1.         1.         0.66666667]\n",
      "Recall :  [1.         0.875      1.         0.33333333 1.         1.        ]\n",
      "F1 :  [0.92307692 0.875      1.         0.5        1.         0.8       ]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  4\n",
      "[21:53:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  0.7272727272727273\n",
      "Precision :  [0.71428571 0.75       0.         0.5        1.         1.        ]\n",
      "Recall :  [0.625      0.85714286 0.         1.         1.         0.75      ]\n",
      "F1 :  [0.66666667 0.8        0.         0.66666667 1.         0.85714286]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  5\n",
      "[21:53:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  0.7142857142857143\n",
      "Precision :  [0.71428571 0.875      0.         0.         1.         1.        ]\n",
      "Recall :  [1.         0.63636364 0.         0.         1.         1.        ]\n",
      "F1 :  [0.83333333 0.73684211 0.         0.         1.         1.        ]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  6\n",
      "[21:53:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  0.8095238095238095\n",
      "Precision :  [0.71428571 0.875      0.         1.         1.        ]\n",
      "Recall :  [0.83333333 0.875      0.         1.         1.        ]\n",
      "F1 :  [0.76923077 0.875      0.         1.         1.        ]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  7\n",
      "[21:53:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  0.7619047619047619\n",
      "Precision :  [0.71428571 0.85714286 0.5        0.         1.         1.        ]\n",
      "Recall :  [0.71428571 0.75       0.5        0.         1.         1.        ]\n",
      "F1 :  [0.71428571 0.8        0.5        0.         1.         1.        ]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  8\n",
      "[21:53:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  0.7142857142857143\n",
      "Precision :  [0.71428571 0.71428571 1.         0.         1.         0.66666667]\n",
      "Recall :  [0.625      0.71428571 0.66666667 0.         1.         1.        ]\n",
      "F1 :  [0.66666667 0.71428571 0.8        0.         1.         0.8       ]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  9\n",
      "[21:53:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  0.8095238095238095\n",
      "Precision :  [1.         0.85714286 0.         1.         1.         0.66666667]\n",
      "Recall :  [0.7        0.85714286 0.         1.         1.         1.        ]\n",
      "F1 :  [0.82352941 0.85714286 0.         1.         1.         0.8       ]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  10\n",
      "[21:53:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  0.6190476190476191\n",
      "Precision :  [0.57142857 0.71428571 0.         1.         1.         0.66666667]\n",
      "Recall :  [0.8        0.55555556 0.         0.5        0.5        1.        ]\n",
      "F1 :  [0.66666667 0.625      0.         0.66666667 0.66666667 0.8       ]\n",
      "-----------------------------------------------\n",
      "Final Mean Scores ---------------------------------\n",
      "Mean Accuracy Score :  0.7519480519480519\n",
      "Mean Precision Score :  0.6987698412698413\n",
      "Mean Recall Score :  0.6691907166907167\n",
      "Mean F1 Score :  0.6682588494237102\n"
     ]
    }
   ],
   "source": [
    "model_fit_predict(glass, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = pd.read_csv('seeds_dataset.txt', sep='\\t', header=None)\n",
    "column_names = ['1', '2', '3', '4', '5', '6', '7', 'label']\n",
    "seeds.columns = column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.26</td>\n",
       "      <td>14.84</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>5.763</td>\n",
       "      <td>3.312</td>\n",
       "      <td>2.221</td>\n",
       "      <td>5.220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.88</td>\n",
       "      <td>14.57</td>\n",
       "      <td>0.8811</td>\n",
       "      <td>5.554</td>\n",
       "      <td>3.333</td>\n",
       "      <td>1.018</td>\n",
       "      <td>4.956</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.29</td>\n",
       "      <td>14.09</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>5.291</td>\n",
       "      <td>3.337</td>\n",
       "      <td>2.699</td>\n",
       "      <td>4.825</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.84</td>\n",
       "      <td>13.94</td>\n",
       "      <td>0.8955</td>\n",
       "      <td>5.324</td>\n",
       "      <td>3.379</td>\n",
       "      <td>2.259</td>\n",
       "      <td>4.805</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.14</td>\n",
       "      <td>14.99</td>\n",
       "      <td>0.9034</td>\n",
       "      <td>5.658</td>\n",
       "      <td>3.562</td>\n",
       "      <td>1.355</td>\n",
       "      <td>5.175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>12.19</td>\n",
       "      <td>13.20</td>\n",
       "      <td>0.8783</td>\n",
       "      <td>5.137</td>\n",
       "      <td>2.981</td>\n",
       "      <td>3.631</td>\n",
       "      <td>4.870</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>11.23</td>\n",
       "      <td>12.88</td>\n",
       "      <td>0.8511</td>\n",
       "      <td>5.140</td>\n",
       "      <td>2.795</td>\n",
       "      <td>4.325</td>\n",
       "      <td>5.003</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>13.20</td>\n",
       "      <td>13.66</td>\n",
       "      <td>0.8883</td>\n",
       "      <td>5.236</td>\n",
       "      <td>3.232</td>\n",
       "      <td>8.315</td>\n",
       "      <td>5.056</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>11.84</td>\n",
       "      <td>13.21</td>\n",
       "      <td>0.8521</td>\n",
       "      <td>5.175</td>\n",
       "      <td>2.836</td>\n",
       "      <td>3.598</td>\n",
       "      <td>5.044</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>12.30</td>\n",
       "      <td>13.34</td>\n",
       "      <td>0.8684</td>\n",
       "      <td>5.243</td>\n",
       "      <td>2.974</td>\n",
       "      <td>5.637</td>\n",
       "      <td>5.063</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         1      2       3      4      5      6      7  label\n",
       "0    15.26  14.84  0.8710  5.763  3.312  2.221  5.220      1\n",
       "1    14.88  14.57  0.8811  5.554  3.333  1.018  4.956      1\n",
       "2    14.29  14.09  0.9050  5.291  3.337  2.699  4.825      1\n",
       "3    13.84  13.94  0.8955  5.324  3.379  2.259  4.805      1\n",
       "4    16.14  14.99  0.9034  5.658  3.562  1.355  5.175      1\n",
       "..     ...    ...     ...    ...    ...    ...    ...    ...\n",
       "205  12.19  13.20  0.8783  5.137  2.981  3.631  4.870      3\n",
       "206  11.23  12.88  0.8511  5.140  2.795  4.325  5.003      3\n",
       "207  13.20  13.66  0.8883  5.236  3.232  8.315  5.056      3\n",
       "208  11.84  13.21  0.8521  5.175  2.836  3.598  5.044      3\n",
       "209  12.30  13.34  0.8684  5.243  2.974  5.637  5.063      3\n",
       "\n",
       "[210 rows x 8 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = seeds.label\n",
    "seeds.drop(['label'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.26</td>\n",
       "      <td>14.84</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>5.763</td>\n",
       "      <td>3.312</td>\n",
       "      <td>2.221</td>\n",
       "      <td>5.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.88</td>\n",
       "      <td>14.57</td>\n",
       "      <td>0.8811</td>\n",
       "      <td>5.554</td>\n",
       "      <td>3.333</td>\n",
       "      <td>1.018</td>\n",
       "      <td>4.956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.29</td>\n",
       "      <td>14.09</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>5.291</td>\n",
       "      <td>3.337</td>\n",
       "      <td>2.699</td>\n",
       "      <td>4.825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.84</td>\n",
       "      <td>13.94</td>\n",
       "      <td>0.8955</td>\n",
       "      <td>5.324</td>\n",
       "      <td>3.379</td>\n",
       "      <td>2.259</td>\n",
       "      <td>4.805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.14</td>\n",
       "      <td>14.99</td>\n",
       "      <td>0.9034</td>\n",
       "      <td>5.658</td>\n",
       "      <td>3.562</td>\n",
       "      <td>1.355</td>\n",
       "      <td>5.175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>12.19</td>\n",
       "      <td>13.20</td>\n",
       "      <td>0.8783</td>\n",
       "      <td>5.137</td>\n",
       "      <td>2.981</td>\n",
       "      <td>3.631</td>\n",
       "      <td>4.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>11.23</td>\n",
       "      <td>12.88</td>\n",
       "      <td>0.8511</td>\n",
       "      <td>5.140</td>\n",
       "      <td>2.795</td>\n",
       "      <td>4.325</td>\n",
       "      <td>5.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>13.20</td>\n",
       "      <td>13.66</td>\n",
       "      <td>0.8883</td>\n",
       "      <td>5.236</td>\n",
       "      <td>3.232</td>\n",
       "      <td>8.315</td>\n",
       "      <td>5.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>11.84</td>\n",
       "      <td>13.21</td>\n",
       "      <td>0.8521</td>\n",
       "      <td>5.175</td>\n",
       "      <td>2.836</td>\n",
       "      <td>3.598</td>\n",
       "      <td>5.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>12.30</td>\n",
       "      <td>13.34</td>\n",
       "      <td>0.8684</td>\n",
       "      <td>5.243</td>\n",
       "      <td>2.974</td>\n",
       "      <td>5.637</td>\n",
       "      <td>5.063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         1      2       3      4      5      6      7\n",
       "0    15.26  14.84  0.8710  5.763  3.312  2.221  5.220\n",
       "1    14.88  14.57  0.8811  5.554  3.333  1.018  4.956\n",
       "2    14.29  14.09  0.9050  5.291  3.337  2.699  4.825\n",
       "3    13.84  13.94  0.8955  5.324  3.379  2.259  4.805\n",
       "4    16.14  14.99  0.9034  5.658  3.562  1.355  5.175\n",
       "..     ...    ...     ...    ...    ...    ...    ...\n",
       "205  12.19  13.20  0.8783  5.137  2.981  3.631  4.870\n",
       "206  11.23  12.88  0.8511  5.140  2.795  4.325  5.003\n",
       "207  13.20  13.66  0.8883  5.236  3.232  8.315  5.056\n",
       "208  11.84  13.21  0.8521  5.175  2.836  3.598  5.044\n",
       "209  12.30  13.34  0.8684  5.243  2.974  5.637  5.063\n",
       "\n",
       "[210 rows x 7 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "Running for fold  1\n",
      "[21:53:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nihal\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\nihal\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.9047619047619048\n",
      "Precision :  [0.85714286 1.         0.85714286]\n",
      "Recall :  [0.85714286 1.         0.85714286]\n",
      "F1 :  [0.85714286 1.         0.85714286]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  2\n",
      "[21:53:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  1.0\n",
      "Precision :  [1. 1. 1.]\n",
      "Recall :  [1. 1. 1.]\n",
      "F1 :  [1. 1. 1.]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  3\n",
      "[21:53:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  0.9047619047619048\n",
      "Precision :  [0.85714286 1.         0.85714286]\n",
      "Recall :  [0.85714286 0.875      1.        ]\n",
      "F1 :  [0.85714286 0.93333333 0.92307692]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  4\n",
      "[21:53:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  0.9047619047619048\n",
      "Precision :  [0.85714286 1.         0.85714286]\n",
      "Recall :  [0.85714286 1.         0.85714286]\n",
      "F1 :  [0.85714286 1.         0.85714286]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  5\n",
      "[21:53:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  0.9523809523809523\n",
      "Precision :  [0.85714286 1.         1.        ]\n",
      "Recall :  [1.    1.    0.875]\n",
      "F1 :  [0.92307692 1.         0.93333333]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  6\n",
      "[21:53:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  1.0\n",
      "Precision :  [1. 1. 1.]\n",
      "Recall :  [1. 1. 1.]\n",
      "F1 :  [1. 1. 1.]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  7\n",
      "[21:53:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  0.9047619047619048\n",
      "Precision :  [0.71428571 1.         1.        ]\n",
      "Recall :  [1.    0.875 0.875]\n",
      "F1 :  [0.83333333 0.93333333 0.93333333]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  8\n",
      "[21:53:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  0.8571428571428571\n",
      "Precision :  [0.71428571 0.85714286 1.        ]\n",
      "Recall :  [0.83333333 1.         0.77777778]\n",
      "F1 :  [0.76923077 0.92307692 0.875     ]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  9\n",
      "[21:53:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  0.9047619047619048\n",
      "Precision :  [1.         0.85714286 0.85714286]\n",
      "Recall :  [0.77777778 1.         1.        ]\n",
      "F1 :  [0.875      0.92307692 0.92307692]\n",
      "-----------------------------------------------\n",
      "-----------------------------------------------\n",
      "Running for fold  10\n",
      "[21:53:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy :  0.9523809523809523\n",
      "Precision :  [1.         1.         0.85714286]\n",
      "Recall :  [0.875 1.    1.   ]\n",
      "F1 :  [0.93333333 1.         0.92307692]\n",
      "-----------------------------------------------\n",
      "Final Mean Scores ---------------------------------\n",
      "Mean Accuracy Score :  0.9285714285714285\n",
      "Mean Precision Score :  0.9285714285714285\n",
      "Mean Recall Score :  0.9349867724867724\n",
      "Mean F1 Score :  0.9281135531135531\n"
     ]
    }
   ],
   "source": [
    "model_fit_predict(seeds, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
